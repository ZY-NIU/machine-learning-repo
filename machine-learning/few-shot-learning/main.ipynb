{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80c131a3",
   "metadata": {},
   "source": [
    "Running in Colab environment.\n",
    "\n",
    "It expects to find the data in the google drive linked with the Colab account. In the google drive, the data should be in '/Kaggle/train/' and '/Kaggle/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "346b4af0",
   "metadata": {
    "id": "346b4af0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8023a184",
   "metadata": {
    "id": "8023a184"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcca9cc",
   "metadata": {
    "id": "9bcca9cc"
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jE5PZ6WAITkx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jE5PZ6WAITkx",
    "outputId": "07b54775-39a2-4a06-d50b-4fdc85a32d96"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "xMPk0SNNyfyv",
   "metadata": {
    "id": "xMPk0SNNyfyv"
   },
   "outputs": [],
   "source": [
    "TRANSFORM_IMG = {\n",
    "    # Train uses data augmentation\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.RandomHorizontalFlip(p=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "    ]),\n",
    "    # Test does not use augmentation\n",
    "    'test':\n",
    "    transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "OQUyKaN5vP8k",
   "metadata": {
    "id": "OQUyKaN5vP8k"
   },
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, root_path, transform=None):\n",
    "        self.data_paths = glob.glob(\"/content/gdrive/MyDrive/Kaggle/train/*/*\")\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.data_paths[idx])\n",
    "        label = self.data_paths[idx].split(\"/\")[-2]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, torch.tensor(int(label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "v0DZ2bLSLIRA",
   "metadata": {
    "id": "v0DZ2bLSLIRA"
   },
   "outputs": [],
   "source": [
    "train_data = TrainDataset(root_path='/content/gdrive/MyDrive/Kaggle/train', transform=TRANSFORM_IMG['train'])\n",
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe73f24b",
   "metadata": {
    "id": "fe73f24b"
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "075a7bfd",
   "metadata": {
    "id": "075a7bfd"
   },
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "def loss_function(predictions, targets):\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    return criterion(predictions, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af223d01",
   "metadata": {
    "id": "af223d01"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94a3e650",
   "metadata": {
    "id": "94a3e650"
   },
   "outputs": [],
   "source": [
    "# CNN Training\n",
    "#\n",
    "# Inputs:\n",
    "#    epoch: epoch #\n",
    "#    model\n",
    "#    optimizer\n",
    "#\n",
    "# Outputs:\n",
    "#    loss\n",
    "#\n",
    "def cnn_train(epoch, model, optimizer):\n",
    "\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (img, category) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        img = img.to(device)\n",
    "        category = category.to(device)\n",
    "        output = model(img)\n",
    "        \n",
    "        loss = loss_function(output, category)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 3 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(img), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(img)))\n",
    "\n",
    "    average_loss = total_loss / len(train_loader.dataset)\n",
    "    print('====> Epoch: {} Average Loss: {:.4f}'.format(\n",
    "          epoch, average_loss))\n",
    "    \n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f262870",
   "metadata": {
    "id": "1f262870"
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "86d751e2",
   "metadata": {
    "id": "86d751e2"
   },
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4YVszXsImwR",
   "metadata": {
    "id": "f4YVszXsImwR"
   },
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "197d600a",
   "metadata": {
    "id": "197d600a"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "model.fc = nn.Linear(2048, 22)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488bad8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "488bad8b",
    "outputId": "a817a589-077f-445f-9dfe-59e5a4e7207c"
   },
   "outputs": [],
   "source": [
    "# train and test cnn\n",
    "epochs = 100\n",
    "average_train_losses = []\n",
    "\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    average_train_loss = cnn_train(epoch, model, optimizer)\n",
    "    average_train_losses.append(average_train_loss)\n",
    "\n",
    "# plot the average train loss\n",
    "plt.plot(average_train_losses)\n",
    "plt.title('Train BCE Losses')\n",
    "plt.ylabel('Binary Cross Entropy')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2473a9",
   "metadata": {
    "id": "2b2473a9"
   },
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2f5e5d9b",
   "metadata": {
    "id": "2f5e5d9b"
   },
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, root_path, transform=None):\n",
    "        self.data_paths = glob.glob(\"/content/gdrive/MyDrive/Kaggle/test/*\")\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.data_paths[idx])\n",
    "        label = self.data_paths[idx].split(\"/\")[-1][:-4]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, int(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_paths)\n",
    "\n",
    "# prepare test image\n",
    "test_data = MyDataset(root_path='/content/gdrive/MyDrive/Kaggle/test', transform=TRANSFORM_IMG['test'])\n",
    "test_loader = DataLoader(test_data, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bea6a050",
   "metadata": {
    "id": "bea6a050"
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "results = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (img, img_id) in enumerate(test_loader):\n",
    "        img = img.to(device)\n",
    "        pred = model(img).argmax()\n",
    "        results.append([int(img_id[0]), int(pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39584b05",
   "metadata": {
    "id": "39584b05"
   },
   "source": [
    "## Export result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d739a4b5",
   "metadata": {
    "id": "d739a4b5"
   },
   "outputs": [],
   "source": [
    "header = ['id', 'category']\n",
    "results.sort(key=lambda s:s[0])\n",
    "\n",
    "with open('result.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "\n",
    "    # write the data\n",
    "    writer.writerows(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa55a3",
   "metadata": {
    "id": "b4aa55a3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project copy 3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
